{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "multi-mono-sf.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MPDRUrEVqf9F"
      },
      "source": [
        "### Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVF_fRkqQN6q"
      },
      "source": [
        "#download the image data\n",
        "%cd /content/\n",
        "!gdown https://drive.google.com/uc?id=1HpFpsQ7VojeJbXj8i9i8IeIzXrzQ5zOs\n",
        "!unzip \"nerf_data.zip\"; rm \"nerf_data.zip\"\n",
        "# !gdown https://drive.google.com/uc?id=1ahp0Ac3I_7Fm1usqPT_Rvgww5KaLvo6Y\n",
        "# !unzip \"rollerblade.zip\"; rm \"rollerblade.zip\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKffmcWPWgB2"
      },
      "source": [
        "%cd /content/\n",
        "!git clone https://github.com/rohaldb/NSFF-custom\n",
        "!mv NSFF-custom Neural-Scene-Flow-Fields\n",
        "%cd /content/Neural-Scene-Flow-Fields\n",
        "!chmod -R +x ./\n",
        "!pip install -r requirements.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFbhZA28nFVm"
      },
      "source": [
        "%cd /content\n",
        "!git clone https://github.com/rohaldb/multi-mono-sf.git\n",
        "%cd multi-mono-sf\n",
        "!chmod -R +x ./\n",
        "!pip install -r requirements.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOmlhij2DfwC"
      },
      "source": [
        "#download nsf depth prediction model and move to appropriate place\n",
        "!gdown https://drive.google.com/uc?id=1ROcvQzxtiBJOFY0MoLWk32emmzNOIAA4\n",
        "!mv model.pt /content/Neural-Scene-Flow-Fields/nsff_scripts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pjYT3bhblqOa"
      },
      "source": [
        "### Execution\n",
        "First run the standard preprocessing pipeline of the neural-scene-flow paper. This will:\n",
        "1. Convert the intrinsics/extrinsics to a special readable format\n",
        "2. Resize the images and run a single view depth model to produce disparity estimates\n",
        "3. Produce optical flow estimates\n",
        "4. Use the optical flow estimates to obtain motion masks\n",
        "\n",
        "We do not use the depth map or the optical flow for custom experiments. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "572ssyJZNgUf"
      },
      "source": [
        "%cd /content/Neural-Scene-Flow-Fields/nsff_scripts\n",
        "# create camera intrinsics/extrinsic format for NSFF, same as original NeRF where it uses imgs2poses.py script from the LLFF code: https://github.com/Fyusion/LLFF/blob/master/imgs2poses.py\n",
        "!python save_poses_nerf.py --data_path \"/content/nerf_data/kid-running/dense/\"\n",
        "# Resize input images and run single view model\n",
        "!python run_midas.py --data_path \"/content/nerf_data/kid-running/dense/\" --input_w 640 --input_h 360 --resize_height 288\n",
        "# Run optical flow model (for easy setup and Pytorch version consistency, we use RAFT as backbond optical flow model, but should be easy to change to other models such as PWC-Net or FlowNet2.0)\n",
        "!./download_models.sh\n",
        "!python run_flows_video.py --model models/raft-things.pth --data_path /content/nerf_data/kid-running/dense/ --epi_threshold 1.0 --input_flow_w 768 --input_semantic_w 1024 --input_semantic_h 576"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dUSFrCrlXSF2"
      },
      "source": [
        "Next we run the mono-sf code, which will produce:\n",
        "1. Disparity maps\n",
        "2. Scene flow estimates\n",
        "3. Induced optical flow estimates\n",
        "\n",
        "By default, it will not produce visualisations to acompany the stored tensors. To include them in the output, add `--save_vis=True` to `eval_kid_running.sh`. The results are stored in various folders within /content/nerf_data/kid-running/dense"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4TnXjfrhwJI"
      },
      "source": [
        "# Run mono-sf to obtain scene flow, induced optical flow and disparity estimates\n",
        "%cd /content/multi-mono-sf/scripts\n",
        "!./eval_kid_running.sh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i55WjXh6X1oA"
      },
      "source": [
        "Next we need to undo the scene flow due to camera ego-motion from mono-sf estimates. The results are stored in /content/nerf_data/kid-running/dense/sf_corrected and /content/nerf_data/kid-running/dense/sf_bw_corrected"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bn-VvfvfX5Pf"
      },
      "source": [
        "%cd /content/Neural-Scene-Flow-Fields/nsff_scripts\n",
        "!python ./account_for_camera_motion.py --datadir \"/content/nerf_data/kid-running/dense\" --final_height 288"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LgXfqA8DO3L2"
      },
      "source": [
        "#save to gdrive\n",
        "%cd /content/\n",
        "!zip -r custom_nerf_data.zip ./nerf_data\n",
        "!cp -r custom_nerf_data.zip /content/drive/MyDrive/Thesis/Data\n",
        "!ls /content/drive/MyDrive/Thesis/Data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LuurTAt6nh5z"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}